data.frame(mus, C1, C12, C13, C14)
xshewhartrunsrules.arl
??"xshewhartrunsrules.arl"
round(cos(x), digits=3)
cat(“Free love starts at”,y,“\n”)
cat(“Free love starts at”,y,“\n”)
cat("Free love starts at”,y,“\n”)
;
:
cat("Free love starts at",y, "\n")
y=3
y
x=5.6643
x
options(digits=2)
x
y=y*20
y
cat("Free love starts at",y, "\n")
for(i in -4:2)
cat(i,"\n")
ages=c(13, 41, 49, 0, 42, 1, 40, 20)
hist(ages)
#This challenge is about famous houses in the pretty town of Brigadoon
distances=c(51,65,175,196,197,125,10,56)	#distances of 8 houses from the town centre in m
bearings=c(10,8,210,25,74,128,235,335)		#bearings of the houses in degrees
#an important point about variables:
#a) always give them descriptive names ("x" is not very informative to someone else looking at your code)
#b) R allows different kinds of variables: scalars and vectors (aka. arrays)
#   scalars are single numbers e.g. x=3
#   vectors are many numbers in an ordered list, e.g. distances and bearings above, and the "c" bit at the start is required by R to tell it that a vector is in the brackets.
xpos=distances*sin(bearings*pi/180)		#in sin and cos the argument MUST be in radians
ypos=distances*cos(bearings*pi/180)		#nb. these are vector calculations - all numbers in distances and bearings are involved
plot(y=ypos,x=xpos,main="Famous Houses in Brigadoon",xlim=c(-200,200),ylim=c(-200,200),xlab="metres east",ylab="metres north")
abline(h=0,lty=1);abline(v=0,lty=1)
numpoints=length(distances)
if (numpoints!=length(bearings)) {stop("the number of bearings and distances don't match")}
nnd=rep(sqrt(2*400*400),times=numpoints)	#start with the maximum possible distance
for (i in 1:numpoints) {
for (j in 1:numpoints) {
if (i!=j) {		#"!=" means "not equal to"
diffx=abs(xpos[i]-xpos[j])
diffy=abs(ypos[i]-ypos[j])
nd=sqrt((diffx^2)+(diffy^2))
if (nd<nnd[i]) {nnd[i]=nd}
}
}
}
cat("Here is the NND for each house in turn:\n")
print(data.frame(xpos,ypos,nnd))
sqrt(50.2^2-8.9^2)
#This challenge is about famous houses in the pretty town of Brigadoon
distances=c(51,65,175,196,197,125,10,56)	#distances of 8 houses from the town centre in m
bearings=c(10,8,210,25,74,128,235,335)		#bearings of the houses in degrees
#an important point about variables:
#a) always give them descriptive names ("x" is not very informative to someone else looking at your code)
#b) R allows different kinds of variables: scalars and vectors (aka. arrays)
#   scalars are single numbers e.g. x=3
#   vectors are many numbers in an ordered list, e.g. distances and bearings above, and the "c" bit at the start is required by R to tell it that a vector is in the brackets.
xpos=distances*sin(bearings*pi/180)		#in sin and cos the argument MUST be in radians
ypos=distances*cos(bearings*pi/180)		#nb. these are vector calculations - all numbers in distances and bearings are involved
f=jpeg(file="plot1jpg")
plot(y=ypos,x=xpos,main="Famous Houses in Brigadoon",xlim=c(-200,200),ylim=c(-200,200),xlab="metres east",ylab="metres north")
abline(h=0,lty=1);abline(v=0,lty=1)
dev.off()
numpoints=length(distances)
if (numpoints!=length(bearings)) {stop("the number of bearings and distances don't match")}
nnd=rep(sqrt(2*400*400),times=numpoints)	#start with the maximum possible distance
for (i in 1:numpoints) {
for (j in 1:numpoints) {
if (i!=j) {		#"!=" means "not equal to"
diffx=abs(xpos[i]-xpos[j])
diffy=abs(ypos[i]-ypos[j])
nd=sqrt((diffx^2)+(diffy^2))
if (nd<nnd[i]) {nnd[i]=nd}
}
}
}
cat("Here is the NND for each house in turn:\n")
print(data.frame(xpos,ypos,nnd))
?jpeg
png(file = "myplot.png", bg = "transparent")
plot(1:10)
rect(1, 5, 3, 7, col = "white")
dev.off()
#This challenge is about famous houses in the pretty town of Brigadoon
distances=c(51,65,175,196,197,125,10,56)	#distances of 8 houses from the town centre in m
bearings=c(10,8,210,25,74,128,235,335)		#bearings of the houses in degrees
#an important point about variables:
#a) always give them descriptive names ("x" is not very informative to someone else looking at your code)
#b) R allows different kinds of variables: scalars and vectors (aka. arrays)
#   scalars are single numbers e.g. x=3
#   vectors are many numbers in an ordered list, e.g. distances and bearings above, and the "c" bit at the start is required by R to tell it that a vector is in the brackets.
xpos=distances*sin(bearings*pi/180)		#in sin and cos the argument MUST be in radians
ypos=distances*cos(bearings*pi/180)		#nb. these are vector calculations - all numbers in distances and bearings are involved
f=jpeg(file="plot1jpg.jpg")
plot(y=ypos,x=xpos,main="Famous Houses in Brigadoon",xlim=c(-200,200),ylim=c(-200,200),xlab="metres east",ylab="metres north")
abline(h=0,lty=1);abline(v=0,lty=1)
dev.off()
numpoints=length(distances)
if (numpoints!=length(bearings)) {stop("the number of bearings and distances don't match")}
nnd=rep(sqrt(2*400*400),times=numpoints)	#start with the maximum possible distance
for (i in 1:numpoints) {
for (j in 1:numpoints) {
if (i!=j) {		#"!=" means "not equal to"
diffx=abs(xpos[i]-xpos[j])
diffy=abs(ypos[i]-ypos[j])
nd=sqrt((diffx^2)+(diffy^2))
if (nd<nnd[i]) {nnd[i]=nd}
}
}
}
cat("Here is the NND for each house in turn:\n")
print(data.frame(xpos,ypos,nnd))
## will make myplot1.jpeg and myplot2.jpeg
jpeg(file = "myplot%d.jpeg")
example(rect)
dev.off()
rect
example(rect)
b=10; c=11; d=12
vec=c(3,bb,8)
vec=c(3,b,b,8)
vec
vec[2]
vec[3]
vec(2)
for(i in 1:4)
cat(vec[i], "\n")
vec2=c(1,2,3,4)
vec3=vec+vec2
vec3
vec4=(vec*vec2)+6
vec4
t(vec)
t(vec)%*%vec2
vv<-t(vec %*% vec2)
vv
vec5<-c(rep(3,times=20))
vec5
mat=matrix(c(7,8,2,3,4,5,6,3,2,1,-2,-9),nrow=3,ncol=4)
mat
mat2=matrix(c(7,8,2,3,4,5,6,3,2,1,-2,- 9),nrow=3,ncol=4,byrow=TRUE)
mat2
mat[2,4]
mat[:,2]
mat[,2]
mat3=matrix(7,nrow=3,ncol=4)
mat3
mat0=matrix(0,nrow=4, ncol=4)
mat0
mat4=matrix(3:14,nrow=3,ncol=4)
mat4
mat4=matrix(3:15,nrow=3,ncol=4)
mat4
mat4[1,]
mat4[3,]
mat4[,2]
mat4[,4]
cat(“x=”,formatC(10.5,width=8,format=“f”,digits=3),“\n”)
cat(“x=”,formatC(10.5,width=8,format=“f”,digits=3),“\n”)
cat(“x=”,formatC(10.5,width=8,format=“f”,digits=3),“\n”)
cat(“x=”,formatC(10.5,width=8,format=“f”,digits=3),“\n”)
cat("x=", format(10.5, width=8, format="f", digits=3), "\n")
nchat("우리나라")
nchar("우리나라")
paste("ab", "c", "d", sep="")
paste(c("a", "b", "c"), collapse="")
dd=as.Date(c("2003-08-24", "2003-11-23", "2004-2-22", "2004-05-03"))
dd
diff(dd)
as.Data("1/1/19 60", format="%d/%m/%Y")
as.Date("1/1/19 60", format="%d/%m/%Y")
as.Date("1/1/1960", format="%d/%m/%Y")
as.integer(as.Date("1/1/1960", format="%d/%m/%Y"))
as.integer(as.Date("30/5/2013", format="%d/%m/%Y"))
as.integer(as.Date("1/1/2000", format="%d/%m/%Y"))
dec1=as.Date("2004-12-1")
dec1
format(dec,format="%b %d %Y")
format(dec1,format="%b %d %Y")
years=c(2004,2005,2006,2007,2008) rainfall=c(1500,1300,1800,1350,1950) plot(x=years,y=rainfall)
years=c(2004,2005,2006,2007,2008)rainfall=c(1500,1300,1800,1350,1950) plot(x=years,y=rainfall)
years=c(2004,2005,2006,2007,2008)
rainfall=c(1500,1300,1800,1350,1950)
plot(x=years,y=rainfall)
thisdata=data.frame(years,rainfall)
bestfit=lm(rainfall years,data=thisdata)
?lm
bestfit=lm(rainfall~years,data=thisdata)
bestfit
demo(graphics)
l
ls()
search()
rm()
ls()
?rm
rm(ls())
rm(list=ls())
ls()
dete.mdy(sdate=15000)
library(date)
library(date)
require(date)
install.packages("date")
library(date)
dete.mdy(sdate=15000)
date.mdy(sdate=15000)
source('/Volumes/JHBae-Data/My Works/[BookCD]/BeginersRcourseKorean/quadrats.r')
#Normally, at the start of an R program you have the various function(s) defined that are used by the program.
#This has to come before the MAIN PROGRAM (which is where your program really starts).
cstest=function(observed,expected,P,doftosubtract) {
brief=FALSE	##For a less detailed report of this test, change this to "brief=TRUE"
if (length(observed)!=length(expected) || !is.finite(sum(observed)) || !is.finite(sum(expected))) {cat("Tidying up data.\n")}
obs=c();exd=c()
for (i in 1:min(length(observed),length(expected))) {
if (is.finite(observed[i]) && is.finite(expected[i])) {obs=c(obs,observed[i]);exd=c(exd,expected[i])}
}
nu=length(obs)-doftosubtract	#nu is the number of degrees of freedom. Subtract 1 if the expected values came from a source independent of the observed values, subtract >1 if you have a contingency table with more than one column or the expected values are derived from e.g. a model fit.
if (nu<1) {
cat("No degrees of freedom - can't do test.\n")
} else {
alpha=(100-P)/100
chisqthresh=qchisq(1-alpha,df=nu)	#this command replaces the old method of looking up the threshold in a statistical table. For me it's not necessary to know anything about the chi-squared distribution itself, but there's an illustration of it at http://www.statsoft.com/textbook/statistics-glossary/c/button/c/#Chi-square%20Distribution if you want to see what's behind this command.
if (!brief) {cat("Threshold is: chi^2_(",alpha,",",nu,") =",chisqthresh,"\n")}
if (nu<2) {
cat("Applying Yates's correction.\n")
chisqstat=sum(((abs(obs-exd)-0.5)^2)/exd)
} else {
chisqstat=sum(((obs-exd)^2)/exd)
}
if (!brief) {cat("Test statistic is: Chi^2 =",chisqstat,"\n")}
pvalue=1-pchisq(chisqstat,df=nu)
pvaluetext1=paste("p=",pvalue)
if (pvalue>0.1) {pvaluetext1="p>0.1"}
if (pvalue<0.001) {pvaluetext1="p<0.001"}
pvaluetext2="not significant"
if (pvalue<0.1) {pvaluetext2="weakly significant"}
if (pvalue<0.05) {pvaluetext2="significant"}
if (pvalue<0.01) {pvaluetext2="highly significant"}
if (pvalue<0.001) {pvaluetext2="very highly significant"}
if (!brief) {cat("At the",P,"% significance level (ie. you're saying that you're only going to reject a null model if there's a <",100-P,"%\nchance that you'll be wrong due to the results being 'coincidence' or 'unusual' (which is always a possibility when\nmaking generalisations about a population from measurements of a sample)):\n")}
if (chisqstat<chisqthresh) {	#equivalent to "if (pvalue>alpha) {"
if (!brief) {cat("\tThe observed values **AGREE** with those predicted by the null hypothesis (i.e. this is not enough evidence to reject the\nnull hypothesis; the data fits the null hypothesis tolerably well; the deviation of observed values from the null hypothesis can be\nexplained by chance alone; observations are what was expected).\n")}
cat("Observations are as expected, so null hypothesis accepted (chi-squared test, n=",length(obs),",",pvaluetext1,").\n")
} else {
if (!brief) {cat("\tThe observed values **ARE DIFFERENT** from those predicted by the null hypothesis (ie. the data doesn't support the\nnull hypothesis; the null hypothesis should be rejected; consider alternative hypotheses)\n")}
if (!brief) {cat("\t(p value for this result is",pvalue,"- a",pvaluetext2,"rejection of the null hypothesis).\n")}
if (mean(obs)<mean(exd)) {cat("Observations are generally lower than expected,")} else {cat("Observations are generally higher than expected,")}
cat(" so null hypothesis rejected (chi-squared test, n=",length(obs),",",pvaluetext1,").\n")
}
}
}
############################
####### MAIN PROGRAM #######
############################
filedata=read.table("quadratdata",header=TRUE)
#reading from file "quadratdata" (just to demonstrate how to do that). Some people use read.delim(...) or read.csv(...), which are basically the same as read.table(...,sep="\t") and read.table(...,sep=","). Sometimes, R reads in a column of numbers, but doesn't recognise the values and labels them as 'factors': if this happens to you, try the solution at https://stat.ethz.ch/pipermail/r-help/2000-February/010165.html.
categories=as.vector(t(filedata[1]))
filedata=read.table("quadratdata",header=TRUE)
#reading from file "quadratdata" (just to demonstrate how to do that). Some people use read.delim(...) or read.csv(...), which are basically the same as read.table(...,sep="\t") and read.table(...,sep=","). Sometimes, R reads in a column of numbers, but doesn't recognise the values and labels them as 'factors': if this happens to you, try the solution at https://stat.ethz.ch/pipermail/r-help/2000-February/010165.html.
categories=as.vector(t(filedata[1]))
#equivalent of categories=c("0","1","2","3","4","5","6","7","8+")
#these categories MUST be mutually exclusive AND exhaustive
observed=as.vector(t(filedata[2]))
#equivalent of observed=c(6,23,25,43,59,54,27,13,10)
#these observed counts must be count data (ie. integers) for this test
if (length(categories)!=length(observed)) {stop("There's something up with the categories and/or observed counts.")}
checkcount=0;for (i in 1:length(observed)) {if (observed[i]<5) {checkcount=checkcount+1}}
if (min(observed)<2 || checkcount>(length(observed)*20/100)) {stop("This result is invalid because you've got too few counts.\nYou need a) all of them >1 and b) less than 20% of them <5 otherwise you can't use a chi-squared test.\nTry grouping your data in to larger categories.\n")}
numquadrats=sum(observed)
estofmean=sum(observed*c(0,1,2,3,4,5,6,7,10))/numquadrats	#assuming mean of the 8+ category is 10.
#I think the hardest bit is always working out the expected values:
probsA=c(rep(0,times=length(observed)))
tmp=trunc(estofmean);if (tmp>(length(observed)-1)) {tmp=length(observed)-1}
probsA[tmp+1]=1			#for a uniform distribution of trees, all quadrats should contain (estofmean) trees
tmp=dpois(0:(length(observed)-2),lambda=estofmean)
probsB=c(tmp,1-sum(tmp))	#for a random distribution, the numbers come from a Poisson distribution
expectedA=numquadrats*probsA
expectedB=numquadrats*probsB
#Now some explanation to the user of what's going on:
cat("You are an ecologist and you have set out some randomly and independently-positioned quadrats, each 10m by 10m, in a\nforest. You have counted the number of trees in each quadrat and your results are in the 'Observed' column of this\ntable (no. of trees in the first column) and the bar plot:\n")
table=data.frame(observed,expectedA,expectedB)
rownames(table)=categories
colnames(table)=c("Observed counts","Expected (A)","Expected (B)")
print(table)
bpmatrix=t(as.matrix(table))
barplot(bpmatrix,beside=TRUE,xlab="no. of trees",ylab="counts",legend=colnames(table))
cat("Total number of quadrats:",numquadrats,"\nEstimated mean number of trees per quadrat (assuming mean of the 8+ category is 10):",estofmean,"\n")
cat("You want to use a chi-squared 'goodness-of-fit' test to assess two null models: a uniform distribution (A) and a\nrandom distribution (B) (your alternative model/theory/hypothesis might be, for example, a clumped distribution). I've\nput the expected values from each of these theories in the table and the bar plot too.\n")
cat("Press a <ENTER> or <RETURN> to continue ");tmp=scan(n=1,quiet=TRUE)
P=95			#using a confidence level of P% (only use 95% or 99% in publications)
cat("\nWith A as the null theory/model/hypothesis:\n")
cstest(observed,expectedA,P,2)	#need to subtract 1 degree of freedom anyway for chi squared, but an extra one because estofmean was used in deriving the expected values
cat("Press a <ENTER> or <RETURN> to continue ");tmp=scan(n=1,quiet=TRUE)
cstest(observed,expectedB,P,2)
#Final comment about the way I've done the test above:
#Most R-users would do a chi-squared test using an in-built R function like this one:
#   pvalue=chisq.test(x=observed,p=expected,rescale.p=TRUE)$p.value
#(read the ?chisq.test manual page for more about how to use this). I'm aware of this, but I generally don't do things that way because all the calculations are hidden from me. It's a shame that R is not written with a 'verbose' option that goes through the calculations step-by-step for you with explanations, but that's the way life is. Why do I need to know what's going on? So that I can a) explain how the test works to someone else and b) if you ever have to do a nonstandard analysis you'll have to learn all about the standard ones in depth anyway.
library("Benchmarking", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
lpSolveAPI
lpSolveAPI
Benchmarking
??Benchmarking
ls()
P
?ls
?rm
rm(list=ls())
ls()
citation()
rep(2,5)
matrix(rep(2,12),ncol=3)
A=matrix(rep(2,12),ncol=3)
A
matrix(A)
diag(A)
seq(from=5, to=4, by=0.5)
?seq
seq(from=3, to=4, by=0.5)
seq(3,4, by=0.5)
seq(3,4,0.5)
seq(3,4,length.out=8)
A<-seq(3,4,length.out=8)
A
rep(A,each=2)
M=matrix(c(1,2,3,4,5,6), ncol=2)
M=matrix(c(1,2,3,4,5,6), ncol=2, byrow=TRUE)
attribute(M)
attribute(M)
attributes(M)
dim(M)
diag(c(1,2,3,4))
A=dim(M)
A
A[1]
A[]
dim(M)[]
dim(M)[2]
M
A=set.seed(2)
A
A=seed(20)
A<-set.seed(30)
A
attributes(A)
class(A)
et.seed(1)
x <- sample(1:10, 25, replace = TRUE)
set.seed(1)
x <- sample(1:10, 25, replace = TRUE)
x
?sample
set.seed(5)
x <- sample(1:10, 25, replace = TRUE)
x
rm(list=rm())
x <- sample(1:10, 25, replace = TRUE)
x
?set.seed
set.seed(1)
x <- sample(1:10, 25, replace = TRUE)
x
x <- sample(1:10, 25, replace = TRUE)
x
?normal
??normal
??'normal distribution'
rnorm(100, mean=0, sd=1)
rnorm(100, mean=0, sd=1)
hist(x)
x=rnorm(100, mean=0, sd=1)
hist(x)
x=rnorm(10000, mean=0, sd=1)
hist(x)
require(graphics)
dnorm(0) == 1/sqrt(2*pi)
dnorm(1) == exp(-1/2)/sqrt(2*pi)
dnorm(1) == 1/sqrt(2*pi*exp(1))
## Using "log = TRUE" for an extended range :
par(mfrow = c(2,1))
plot(function(x) dnorm(x, log = TRUE), -60, 50,
main = "log { Normal density }")
curve(log(dnorm(x)), add = TRUE, col = "red", lwd = 2)
mtext("dnorm(x, log=TRUE)", adj = 0)
mtext("log(dnorm(x))", col = "red", adj = 1)
plot(function(x) pnorm(x, log.p = TRUE), -50, 10,
main = "log { Normal Cumulative }")
curve(log(pnorm(x)), add = TRUE, col = "red", lwd = 2)
mtext("pnorm(x, log=TRUE)", adj = 0)
mtext("log(pnorm(x))", col = "red", adj = 1)
## if you want the so-called 'error function'
erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1
## (see Abramowitz and Stegun 29.2.29)
## and the so-called 'complementary error function'
erfc <- function(x) 2 * pnorm(x * sqrt(2), lower = FALSE)
## and the inverses
erfinv <- function (x) qnorm((1 + x)/2)/sqrt(2)
erfcinv <- function (x) qnorm(x/2, lower = FALSE)/sqrt(2)
plot(function(x) dnorm(x, log = FALSE), -60, 50,
+      main = "log { Normal density }")
plot(function(x) dnorm(x, log = FALSE), -60, 50,
+      main = "log { Normal density }")
plot(function(x) dnorm(x, log = FALSE), -60, 50,
+      main = "log{Normal Denst.}"
x
function(x)
rnormal(x)
?log
q()
require(pmr)
install.packages("pmr")
require(pmr)
abc <- matrix(data = 1:15, nrow = 4, ncol = 4, byrow = TRUE)
abc[1,1] <- 1
abc[1,2] <- 2
abc[1,3] <- 5
abc[1,4] <- 4
abc[2,1] <- 1/2
abc[2,2] <- 1
abc[2,3] <- 3
abc[2,4] <- 1.9
abc[3,1] <- 1/5
abc[3,2] <- 1/3
abc[3,3] <- 1
abc[3,4] <- 0.7
abc[4,1] <- 1/4
abc[4,2] <- 1/1.9
abc[4,3] <- 1/0.7
abc[4,4] <- 1
ahp(abc)
?ahp
ahp(abc, sim_size=300)
load('pmr')
library('pmr')
ahp(abc)
## ahp(abc)
ahp
ahp
?pmr
pmr
pmr
load.package(pmr)
load.packages(pmr)
library('pmr')
require('pmr')
pmr
ls()
ahp
library('pmr')
ahp(abc)
ahp('abc')
?ahp
citation()
rm(list=ls())
require('pmr')
abc <- matrix(data = 1:15, nrow = 4, ncol = 4, byrow = TRUE)
abc <- matrix(data = 1:16, nrow = 4, ncol = 4, byrow = TRUE)
abc <- matrix(data = 1:16, nrow = 4, ncol = 4, byrow = TRUE)
abc
abc[1,1] <- 1
abc[1,2] <- 2
abc[1,3] <- 5
abc[1,4] <- 4
abc[2,1] <- 1/2
abc[2,2] <- 1
abc[2,3] <- 3
abc[2,4] <- 1.9
abc[3,1] <- 1/5
abc[3,2] <- 1/3
abc[3,3] <- 1
abc[3,4] <- 0.7
abc[4,1] <- 1/4
abc[4,2] <- 1/1.9
abc[4,3] <- 1/0.7
abc[4,4] <- 1
abc
ahp(abc)
install.packages("knitr")
library("codetools", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
install.packages(c("car", "class", "evaluate", "formatR", "gdata", "gtools", "Hmisc", "knitr", "labeling", "markdown", "MASS", "mgcv", "munsell", "mvtnorm", "nlme", "nnet", "pmr", "rgl", "rms", "RODBC", "spatial", "zoo"))
q()
1024*4
library("qcc")
?qcc
cl <- makeCluster(3, type="SOCK", master="192.168.1.100") setDefaultClusterOptions(outfile="")
ls()
observed
bpmatrix
type(bpmatrix)
class(bpmatrix)
typeof(bpmatri)
typeof(bpmatrix)
setwd("/Volumes/JHBae-Data/G-Drive/Code/QCData/20140422")
getwd()
source("main.r")
main()
source("oscSimul.r")
oscSimul()
main()
main()
main()
oscSimul()
source("oscSimul.r")
oscSimul()
oscSimul()
source("oscSimul.r")
main()
main()
oscSimul()
